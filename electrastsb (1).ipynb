{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n    \n\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nimport tqdm\nimport random\nfrom tensorflow.keras import backend as K\nfrom sklearn.model_selection import StratifiedKFold\nfrom scipy.stats import pearsonr\n\nfrom transformers import AutoTokenizer, TFAutoModel\nimport transformers\n\nfrom datasets import Dataset\nimport tensorflow_probability as tfp\nfrom tensorflow.python.ops import array_ops\nfrom tensorflow.python.ops import math_ops\nimport gc\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-12T13:16:03.806389Z","iopub.execute_input":"2022-06-12T13:16:03.806882Z","iopub.status.idle":"2022-06-12T13:16:13.627092Z","shell.execute_reply.started":"2022-06-12T13:16:03.80677Z","shell.execute_reply":"2022-06-12T13:16:13.626477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try:\n    # TPU config\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n    auto = tf.data.experimental.AUTOTUNE\n    replicas = strategy.num_replicas_in_sync\n    print(f'TPU: {tpu.master()}')\nexcept:\n    strategy = tf.distribute.get_strategy()\n    auto = tf.data.experimental.AUTOTUNE\n    replicas = strategy.num_replicas_in_sync\n\n# XLA acceleartion\ntf.config.optimizer.set_jit(True)\nprint(f'Replicas: {replicas}')","metadata":{"execution":{"iopub.status.busy":"2022-06-12T13:16:13.628462Z","iopub.execute_input":"2022-06-12T13:16:13.628786Z","iopub.status.idle":"2022-06-12T13:16:19.59111Z","shell.execute_reply.started":"2022-06-12T13:16:13.62876Z","shell.execute_reply":"2022-06-12T13:16:19.590452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Electra (Inspired by: https://www.kaggle.com/code/mohamadmerchant/us-phrase-matching-tf-keras-train-tpu)\n","metadata":{}},{"cell_type":"code","source":"class Config():\n    seed = 69\n    epochs = 40\n    num_folds = 5\n    max_length = 412\n    batch_size = 128\n    # THIS LEARNING RATE IS FOR THE TRANSFORMER\n#     lr1 = 1e-6 FOR BASE\n# FOR LARGE\n    lr1 = 1e-10\n    \n    # THIS LEARNING RATE IS FOR THE OUTPUT\n    lr2 = 1e-4\n#     base = \"howey/electra-base-stsb\"\n    base = \"howey/electra-large-stsb\"\n#     base = \"google/electra-base-generator\"\n#     base = \"google/electra-base-discriminator\"\n    shuffle = True\n    \n    def __init__(self, **kwargs):\n        for k, v in kwargs.items():\n            setattr(self, k, v)\n            \ndef seed_everything(seed=69):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n    \nseed_everything(seed=69)\nconfig = Config()","metadata":{"execution":{"iopub.status.busy":"2022-06-12T13:16:19.592081Z","iopub.execute_input":"2022-06-12T13:16:19.592937Z","iopub.status.idle":"2022-06-12T13:16:19.600678Z","shell.execute_reply.started":"2022-06-12T13:16:19.592901Z","shell.execute_reply":"2022-06-12T13:16:19.59961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(config.base, special_tokens=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-12T13:16:19.603011Z","iopub.execute_input":"2022-06-12T13:16:19.603519Z","iopub.status.idle":"2022-06-12T13:16:21.983896Z","shell.execute_reply.started":"2022-06-12T13:16:19.603475Z","shell.execute_reply":"2022-06-12T13:16:21.982961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"codes = pd.read_csv(\"../input/cpc-codes/titles.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-06-12T13:16:21.985206Z","iopub.execute_input":"2022-06-12T13:16:21.985563Z","iopub.status.idle":"2022-06-12T13:16:23.160854Z","shell.execute_reply.started":"2022-06-12T13:16:21.985525Z","shell.execute_reply":"2022-06-12T13:16:23.16001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mapping = dict(zip(codes.code, codes.title))","metadata":{"execution":{"iopub.status.busy":"2022-06-12T13:16:23.161909Z","iopub.execute_input":"2022-06-12T13:16:23.16214Z","iopub.status.idle":"2022-06-12T13:16:23.312369Z","shell.execute_reply.started":"2022-06-12T13:16:23.162112Z","shell.execute_reply":"2022-06-12T13:16:23.311433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def process_data(file_path):\n    file = pd.read_csv(f\"../input/us-patent-phrase-to-phrase-matching/{file_path}\")\n    file[\"context_text\"] = file[\"context\"].map(lambda code: mapping.get(code, \"\"))\n    file[\"section_context\"] = \"[\" + file.context.str[0] + \"]\"\n    file[\"input\"] = file.section_context + \" \" + file.context_text.str.lower() + \" [SEP] \" + file.anchor.str.lower() + \" [SEP] \" + file.target.str.lower()\n    return file","metadata":{"execution":{"iopub.status.busy":"2022-06-12T13:16:23.313555Z","iopub.execute_input":"2022-06-12T13:16:23.313804Z","iopub.status.idle":"2022-06-12T13:16:23.32487Z","shell.execute_reply.started":"2022-06-12T13:16:23.313775Z","shell.execute_reply":"2022-06-12T13:16:23.323876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = process_data(\"train.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-06-12T13:16:23.32607Z","iopub.execute_input":"2022-06-12T13:16:23.326347Z","iopub.status.idle":"2022-06-12T13:16:23.592393Z","shell.execute_reply.started":"2022-06-12T13:16:23.326306Z","shell.execute_reply":"2022-06-12T13:16:23.591511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"context_tokens = list(train.section_context.unique())\ntokenizer.add_special_tokens({'additional_special_tokens': context_tokens})","metadata":{"execution":{"iopub.status.busy":"2022-06-12T13:16:23.593963Z","iopub.execute_input":"2022-06-12T13:16:23.594278Z","iopub.status.idle":"2022-06-12T13:16:23.606711Z","shell.execute_reply.started":"2022-06-12T13:16:23.594238Z","shell.execute_reply":"2022-06-12T13:16:23.606097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = process_data(\"test.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-06-12T13:16:23.609016Z","iopub.execute_input":"2022-06-12T13:16:23.609743Z","iopub.status.idle":"2022-06-12T13:16:23.625594Z","shell.execute_reply.started":"2022-06-12T13:16:23.609704Z","shell.execute_reply":"2022-06-12T13:16:23.624815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prepare_for_model(data, shuffle=True):\n    inputs = tokenizer(list(data[\"input\"].values), padding = \"max_length\", max_length = config.max_length, truncation = True)\n    \n    dataset = \"\"\n    if shuffle:\n        dataset = tf.data.Dataset.from_tensor_slices((inputs.data, data['score'].tolist())).shuffle(1024).batch(config.batch_size).prefetch(tf.data.AUTOTUNE)\n        \n    else:\n        dataset = tf.data.Dataset.from_tensor_slices((inputs.data, data['score'].tolist())).batch(config.batch_size).prefetch(tf.data.AUTOTUNE)\n    \n    \n    return dataset","metadata":{"execution":{"iopub.status.busy":"2022-06-12T13:16:23.627041Z","iopub.execute_input":"2022-06-12T13:16:23.627507Z","iopub.status.idle":"2022-06-12T13:16:23.634662Z","shell.execute_reply.started":"2022-06-12T13:16:23.627473Z","shell.execute_reply":"2022-06-12T13:16:23.633775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def correlationLoss(y_actual, y_pred, axis=-2):\n    \"\"\"Metric returning the Pearson correlation coefficient of two tensors over some axis, default -2.\"\"\"\n#     import pdb; pdb.set_trace()\n    #Ignore the bad variables names here I didn't write this code\n    x = tf.convert_to_tensor(y_actual)\n    y = math_ops.cast(y_pred, x.dtype)\n    n = tf.cast(tf.shape(x)[axis], x.dtype)\n    xsum = tf.reduce_sum(x, axis=axis)\n    ysum = tf.reduce_sum(y, axis=axis)\n    xmean = xsum / n\n    ymean = ysum / n\n    xvar = tf.reduce_sum( tf.math.squared_difference(x, xmean), axis=axis)\n    yvar = tf.reduce_sum( tf.math.squared_difference(y, ymean), axis=axis)\n    cov = tf.reduce_sum( (x - xmean) * (y - ymean), axis=axis)\n    corr = cov / tf.sqrt(xvar * yvar)\n    return tf.constant(1.0, dtype=x.dtype) - corr","metadata":{"execution":{"iopub.status.busy":"2022-06-12T13:16:23.635658Z","iopub.execute_input":"2022-06-12T13:16:23.635869Z","iopub.status.idle":"2022-06-12T13:16:23.650401Z","shell.execute_reply.started":"2022-06-12T13:16:23.635837Z","shell.execute_reply":"2022-06-12T13:16:23.649664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def createElectra(config):\n    with strategy.scope():\n        steps_per_epoch = 36473 // config.batch_size\n        \n        clr1 = tfa.optimizers.CyclicalLearningRate(initial_learning_rate=config.lr1 / 10,\n            maximal_learning_rate=config.lr1,\n            scale_fn=lambda x: 1/(2.**(x-1)),\n            step_size=2 * steps_per_epoch\n        )\n        \n        clr2 = tfa.optimizers.CyclicalLearningRate(initial_learning_rate=config.lr2 / 10,\n            maximal_learning_rate=config.lr2,\n            scale_fn=lambda x: 1/(2.**(x-1)),\n            step_size=2 * steps_per_epoch\n        )\n        \n        \n        input_ids = tf.keras.layers.Input(\n            shape=(config.max_length,), dtype=tf.int32, name=\"input_ids\"\n        )\n\n        attention_masks = tf.keras.layers.Input(\n            shape=(config.max_length,), dtype=tf.int32, name=\"attention_mask\"\n        )\n        \n        token_type_ids = tf.keras.layers.Input(\n            shape=(config.max_length,), dtype=tf.int32, name=\"token_type_ids\"\n        )\n\n        base_model = transformers.TFAutoModel.from_pretrained(config.base, from_pt=True)\n\n        base_model_output = base_model(\n            input_ids, attention_mask=attention_masks, token_type_ids=token_type_ids\n        )\n\n        last_hidden_state = base_model_output.last_hidden_state[:, 0, :]\n        \n        dropout = tf.keras.layers.Dropout(base_model.config.hidden_dropout_prob)(last_hidden_state)\n        \n        dense = tf.keras.layers.Dense(base_model.config.hidden_size, activation = \"gelu\")(dropout)\n        \n        dropout = tf.keras.layers.Dropout(base_model.config.hidden_dropout_prob)(dense)\n        \n        model_output = tf.keras.layers.Dense(1, activation = \"sigmoid\")(dropout)\n        \n        model = tf.keras.models.Model(\n            inputs=[input_ids, attention_masks, token_type_ids], outputs=model_output\n        )\n        \n#         optimizers = [\n#             tfa.optimizers.AdamW(weight_decay=config.weight_decay, learning_rate=config.lr1),\n#             tfa.optimizers.AdamW(weight_decay=config.weight_decay, learning_rate=config.lr2)\n#         ]\n        \n        optimizers = [\n            tf.keras.optimizers.Adam(learning_rate=clr1),\n            tf.keras.optimizers.Adam(learning_rate=clr2)\n        ]\n        \n        optimizers_and_layers = [(optimizers[0], model.layers[0:4]), (optimizers[1], model.layers[3:])]\n        optimizer = tfa.optimizers.MultiOptimizer(optimizers_and_layers)\n        \n        \n#         loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits = False)\n        loss_fn = correlationLoss\n\n        model.compile(\n            optimizer = optimizer,\n            loss=loss_fn,\n            steps_per_execution=steps_per_epoch\n        )\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-06-12T13:16:23.651759Z","iopub.execute_input":"2022-06-12T13:16:23.652381Z","iopub.status.idle":"2022-06-12T13:16:23.669453Z","shell.execute_reply.started":"2022-06-12T13:16:23.652323Z","shell.execute_reply":"2022-06-12T13:16:23.668699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config = Config()\nm = createElectra(config)","metadata":{"execution":{"iopub.status.busy":"2022-06-12T13:16:23.670569Z","iopub.execute_input":"2022-06-12T13:16:23.671037Z","iopub.status.idle":"2022-06-12T13:18:09.531209Z","shell.execute_reply.started":"2022-06-12T13:16:23.670998Z","shell.execute_reply":"2022-06-12T13:18:09.530313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"m.summary()","metadata":{"execution":{"iopub.status.busy":"2022-06-12T13:18:09.532581Z","iopub.execute_input":"2022-06-12T13:18:09.532897Z","iopub.status.idle":"2022-06-12T13:18:09.57437Z","shell.execute_reply.started":"2022-06-12T13:18:09.532859Z","shell.execute_reply":"2022-06-12T13:18:09.57344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_folds(train, config):\n    \n    oof = np.zeros(config.num_folds)\n    \n    skf = StratifiedKFold(n_splits=config.num_folds, \n                      shuffle=True,\n                      random_state=config.seed)\n    \n    train['score_map'] = train['score'].map({0.00: 0, 0.25: 1, 0.50: 2, 0.75: 3, 1.00: 4})\n    for fold, (train_idx, val_idx) in enumerate(skf.split(train, train[\"score_map\"])):\n        print(\"*\" * 25)\n        print(f\"Training fold: {fold+1}\")\n\n        K.clear_session()\n        tf.tpu.experimental.initialize_tpu_system(tpu)\n        train_df = train.loc[train_idx].reset_index(drop=True)\n        val_df = train.loc[val_idx].reset_index(drop=True)\n        \n        \n        train_set = prepare_for_model(train_df)\n        val_set = prepare_for_model(val_df, shuffle = False)\n\n        checkpoint = tf.keras.callbacks.ModelCheckpoint(f'model-{fold+1}.h5',\n                                                        monitor='val_loss',\n                                                        mode='min',\n                                                        save_best_only=True,\n                                                        save_weights_only=True,\n                                                        save_freq='epoch',\n                                                        verbose=1)\n        \n        early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n                                                          mode='min',\n                                                          patience=6,\n                                                          verbose=1)\n        \n\n        \n        model = createElectra(config)\n        history = model.fit(\n                        train_set,\n                        validation_data=val_set,\n                        epochs=config.epochs,\n                        callbacks=[checkpoint, \n                                   early_stopping],\n                        verbose=1\n                    )\n        \n#         import pdb; pdb.set_trace()\n        model.load_weights(f'model-{fold+1}.h5')\n        y_hat = model.predict(val_set, batch_size = config.batch_size).reshape(-1)\n        performance = pearsonr(y_hat, val_df[\"score\"].tolist())[0]\n        oof[fold] = performance\n#         model.save(f'electra-large-{fold + 1}')\n        del model\n        gc.collect()\n        print(f\"PearsonR: {performance}\")\n    \n    \n    return oof","metadata":{"execution":{"iopub.status.busy":"2022-06-12T13:18:09.575631Z","iopub.execute_input":"2022-06-12T13:18:09.575903Z","iopub.status.idle":"2022-06-12T13:18:09.592448Z","shell.execute_reply.started":"2022-06-12T13:18:09.575872Z","shell.execute_reply":"2022-06-12T13:18:09.591468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config = Config()\nelectras = train_folds(train, config)","metadata":{"execution":{"iopub.status.busy":"2022-06-12T13:18:09.593872Z","iopub.execute_input":"2022-06-12T13:18:09.594194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"electras","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.mean(electras)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}