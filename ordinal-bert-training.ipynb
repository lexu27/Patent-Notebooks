{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n    \n\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nimport tqdm\nimport random\nfrom tensorflow.keras import backend as K\nfrom sklearn.model_selection import StratifiedKFold\nfrom scipy.stats import pearsonr\n\nfrom transformers import AutoTokenizer, TFAutoModel\nimport transformers\n\nfrom datasets import Dataset\nimport tensorflow_probability as tfp\nfrom tensorflow.python.ops import array_ops\nfrom tensorflow.python.ops import math_ops\nimport gc\n!pip install coral-ordinal\nimport coral_ordinal as coral\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-16T00:21:08.153314Z","iopub.execute_input":"2022-06-16T00:21:08.153851Z","iopub.status.idle":"2022-06-16T00:21:27.147422Z","shell.execute_reply.started":"2022-06-16T00:21:08.153724Z","shell.execute_reply":"2022-06-16T00:21:27.146305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! pip install -q chemparse\n! pip install -q pyvalem\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport pickle\nfrom pyvalem.formula import Formula\nimport chemparse","metadata":{"execution":{"iopub.status.busy":"2022-06-16T00:21:27.149909Z","iopub.execute_input":"2022-06-16T00:21:27.15042Z","iopub.status.idle":"2022-06-16T00:21:43.550834Z","shell.execute_reply.started":"2022-06-16T00:21:27.150369Z","shell.execute_reply":"2022-06-16T00:21:43.5499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('../input/periodictable/periodic_table.p', 'rb') as fin:\n    per_table = pickle.load(fin)\n\ndef atoms_to_str(atoms):\n    return ' '.join([per_table.get(x.lower(), '') for x in atoms])\n    \ndef parse_formula(text):\n    tokenized = text.split(' ')\n    \n    results = []\n    \n    for tok in tokenized:\n        atoms = chemparse.parse_formula(tok).keys()\n        formula = atoms_to_str(atoms)\n        if len(formula) < 2 or len(tok) < 3:\n            results.append(tok)\n        else:\n            try:\n                f = Formula(tok.upper())\n                atoms = f.atoms\n                formula = ' '.join([x.name.lower() for x in atoms])\n            except Exception as e:\n                pass\n            \n            results.append(formula)\n    \n    return ' '.join(results)\n \ndef parse_df_formulas(df):\n    df = df.copy()\n    df.loc[:, 'target'] = df.target.apply(parse_formula)\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-06-16T00:21:43.552522Z","iopub.execute_input":"2022-06-16T00:21:43.55276Z","iopub.status.idle":"2022-06-16T00:21:43.567481Z","shell.execute_reply.started":"2022-06-16T00:21:43.55273Z","shell.execute_reply":"2022-06-16T00:21:43.566854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try:\n    # TPU config\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n    auto = tf.data.experimental.AUTOTUNE\n    replicas = strategy.num_replicas_in_sync\n    print(f'TPU: {tpu.master()}')\nexcept:\n    strategy = tf.distribute.get_strategy()\n    auto = tf.data.experimental.AUTOTUNE\n    replicas = strategy.num_replicas_in_sync\n\n# XLA acceleartion\ntf.config.optimizer.set_jit(True)\nprint(f'Replicas: {replicas}')","metadata":{"execution":{"iopub.status.busy":"2022-06-16T00:21:43.569699Z","iopub.execute_input":"2022-06-16T00:21:43.570032Z","iopub.status.idle":"2022-06-16T00:21:50.092968Z","shell.execute_reply.started":"2022-06-16T00:21:43.570002Z","shell.execute_reply":"2022-06-16T00:21:50.092062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# BertLegal (Inspired by: https://www.kaggle.com/code/mohamadmerchant/us-phrase-matching-tf-keras-train-tpu)\n","metadata":{}},{"cell_type":"code","source":"class Config():\n    seed = 69\n    epochs = 40\n    num_folds = 5\n    max_length = 412\n    batch_size = 32\n    # THIS LEARNING RATE IS FOR THE TRANSFORMER\n    lr1 = 1e-10\n    \n    # THIS LEARNING RATE IS FOR THE OUTPUT\n    lr2 = 1e-4\n    base = \"anferico/bert-for-patents\"\n    shuffle = True\n    \n    def __init__(self, **kwargs):\n        for k, v in kwargs.items():\n            setattr(self, k, v)\n            \ndef seed_everything(seed=69):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n    \nseed_everything(seed=69)\nconfig = Config()","metadata":{"execution":{"iopub.status.busy":"2022-06-16T01:06:09.959563Z","iopub.execute_input":"2022-06-16T01:06:09.962238Z","iopub.status.idle":"2022-06-16T01:06:09.971137Z","shell.execute_reply.started":"2022-06-16T01:06:09.962194Z","shell.execute_reply":"2022-06-16T01:06:09.970494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(config.base, special_tokens=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-16T00:21:50.103882Z","iopub.execute_input":"2022-06-16T00:21:50.104229Z","iopub.status.idle":"2022-06-16T00:21:51.832982Z","shell.execute_reply.started":"2022-06-16T00:21:50.10419Z","shell.execute_reply":"2022-06-16T00:21:51.832071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"codes = pd.read_csv(\"../input/cpc-codes/titles.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-06-16T00:21:51.834254Z","iopub.execute_input":"2022-06-16T00:21:51.834497Z","iopub.status.idle":"2022-06-16T00:21:52.66905Z","shell.execute_reply.started":"2022-06-16T00:21:51.834468Z","shell.execute_reply":"2022-06-16T00:21:52.668197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mapping = dict(zip(codes.code, codes.title))","metadata":{"execution":{"iopub.status.busy":"2022-06-16T00:21:52.670082Z","iopub.execute_input":"2022-06-16T00:21:52.670318Z","iopub.status.idle":"2022-06-16T00:21:52.825539Z","shell.execute_reply.started":"2022-06-16T00:21:52.670289Z","shell.execute_reply":"2022-06-16T00:21:52.824452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def process_data(file_path):\n    file = pd.read_csv(f\"../input/us-patent-phrase-to-phrase-matching/{file_path}\")\n    file = parse_df_formulas(file)\n    file[\"context_text\"] = file[\"context\"].map(lambda code: mapping.get(code, \"\"))\n    file[\"section_context\"] = \"[\" + file.context.str[0] + \"]\"\n    file[\"input\"] = file.section_context + \" \" + file.context_text.str.lower() + \" [SEP] \" + file.anchor.str.lower() + \" [SEP] \" + file.target.str.lower()\n    file[\"y\"] = file.score * 4\n    return file","metadata":{"execution":{"iopub.status.busy":"2022-06-16T00:21:52.827102Z","iopub.execute_input":"2022-06-16T00:21:52.827499Z","iopub.status.idle":"2022-06-16T00:21:52.836522Z","shell.execute_reply.started":"2022-06-16T00:21:52.827455Z","shell.execute_reply":"2022-06-16T00:21:52.835853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = process_data(\"train.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-06-16T00:21:52.838692Z","iopub.execute_input":"2022-06-16T00:21:52.839258Z","iopub.status.idle":"2022-06-16T00:21:55.075986Z","shell.execute_reply.started":"2022-06-16T00:21:52.839228Z","shell.execute_reply":"2022-06-16T00:21:55.07517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-16T00:21:55.077219Z","iopub.execute_input":"2022-06-16T00:21:55.077816Z","iopub.status.idle":"2022-06-16T00:21:55.100287Z","shell.execute_reply.started":"2022-06-16T00:21:55.077785Z","shell.execute_reply":"2022-06-16T00:21:55.099708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"context_tokens = list(train.section_context.unique())\ntokenizer.add_special_tokens({'additional_special_tokens': context_tokens})","metadata":{"execution":{"iopub.status.busy":"2022-06-16T00:21:55.101281Z","iopub.execute_input":"2022-06-16T00:21:55.102058Z","iopub.status.idle":"2022-06-16T00:21:55.111425Z","shell.execute_reply.started":"2022-06-16T00:21:55.102025Z","shell.execute_reply":"2022-06-16T00:21:55.1104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prepare_for_model(data, train):\n    inputs = tokenizer(list(data[\"input\"].values), padding = \"max_length\", max_length = config.max_length, truncation = True)\n    \n    dataset = \"\"\n    if train:\n        dataset = tf.data.Dataset.from_tensor_slices((inputs.data, data['y'].tolist())).shuffle(1024).batch(config.batch_size).prefetch(tf.data.AUTOTUNE)\n    else:\n        dataset = tf.data.Dataset.from_tensor_slices(inputs.data).batch(config.batch_size).prefetch(tf.data.AUTOTUNE)\n    \n    \n    return dataset","metadata":{"execution":{"iopub.status.busy":"2022-06-16T00:21:55.112628Z","iopub.execute_input":"2022-06-16T00:21:55.112932Z","iopub.status.idle":"2022-06-16T00:21:55.11941Z","shell.execute_reply.started":"2022-06-16T00:21:55.112897Z","shell.execute_reply":"2022-06-16T00:21:55.11858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def createBERT(config):\n    with strategy.scope():\n        steps_per_epoch = 36473 // config.batch_size\n        \n        clr1 = tfa.optimizers.CyclicalLearningRate(initial_learning_rate=config.lr1 / 10,\n            maximal_learning_rate=config.lr1,\n            scale_fn=lambda x: 1/(2.**(x-1)),\n            step_size=2 * steps_per_epoch\n        )\n        \n        clr2 = tfa.optimizers.CyclicalLearningRate(initial_learning_rate=config.lr2 / 10,\n            maximal_learning_rate=config.lr2,\n            scale_fn=lambda x: 1/(2.**(x-1)),\n            step_size=2 * steps_per_epoch\n        )\n        \n        \n        input_ids = tf.keras.layers.Input(\n            shape=(config.max_length,), dtype=tf.int32, name=\"input_ids\"\n        )\n\n        attention_masks = tf.keras.layers.Input(\n            shape=(config.max_length,), dtype=tf.int32, name=\"attention_mask\"\n        )\n        \n        token_type_ids = tf.keras.layers.Input(\n            shape=(config.max_length,), dtype=tf.int32, name=\"token_type_ids\"\n        )\n\n        base_model = transformers.TFAutoModel.from_pretrained(config.base, from_pt=True)\n\n        base_model_output = base_model(\n            input_ids, attention_mask=attention_masks, token_type_ids=token_type_ids\n        )\n\n        last_hidden_state = base_model_output.last_hidden_state[:, 0, :]\n        \n        dropout = tf.keras.layers.Dropout(base_model.config.hidden_dropout_prob)(last_hidden_state)\n        \n        dense = tf.keras.layers.Dense(base_model.config.hidden_size, activation = \"tanh\")(dropout)\n        \n        dropout = tf.keras.layers.Dropout(base_model.config.hidden_dropout_prob)(dense)\n        \n        model_output = coral.CoralOrdinal(num_classes = 5)(dropout)\n        \n        model = tf.keras.models.Model(\n            inputs=[input_ids, attention_masks, token_type_ids], outputs=model_output\n        )\n        \n#         optimizers = [\n#             tfa.optimizers.AdamW(weight_decay=config.weight_decay, learning_rate=config.lr1),\n#             tfa.optimizers.AdamW(weight_decay=config.weight_decay, learning_rate=config.lr2)\n#         ]\n        \n        optimizers = [\n            tf.keras.optimizers.Adam(learning_rate=clr1),\n            tf.keras.optimizers.Adam(learning_rate=clr2)\n        ]\n        \n        optimizers_and_layers = [(optimizers[0], model.layers[0:4]), (optimizers[1], model.layers[3:])]\n        optimizer = tfa.optimizers.MultiOptimizer(optimizers_and_layers)\n        \n        \n#         loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits = False)\n        importance_weights = [0.1, 0.2, 0.3, 0.4]\n        loss_fn = coral.OrdinalCrossEntropy(importance_weights = importance_weights)\n\n        model.compile(\n            optimizer = optimizer,\n            loss=loss_fn,\n        )\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-06-16T00:21:55.121975Z","iopub.execute_input":"2022-06-16T00:21:55.122303Z","iopub.status.idle":"2022-06-16T00:21:55.138609Z","shell.execute_reply.started":"2022-06-16T00:21:55.122262Z","shell.execute_reply":"2022-06-16T00:21:55.138014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config = Config()\ncreateBERT(config).summary()","metadata":{"execution":{"iopub.status.busy":"2022-06-16T00:21:55.139968Z","iopub.execute_input":"2022-06-16T00:21:55.140438Z","iopub.status.idle":"2022-06-16T00:23:35.846782Z","shell.execute_reply.started":"2022-06-16T00:21:55.140405Z","shell.execute_reply":"2022-06-16T00:23:35.845778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from scipy import special\nclass Pearsonr(tf.keras.callbacks.Callback):\n    def __init__(self, val_data, y_val):\n        self.val_data = val_data\n        self.y_val = y_val\n    def on_epoch_end(self, epoch, logs):\n        import pdb; pdb.set_trace() \n        logits = model.predict(self.val_data, batch_size = config.batch_size).reshape(-1)\n        \n        y_hat = tf.math.sigmoid(logits)\n        \n        y_hat = coral.cumprobs_to_label(y_hat, threshold = 0.5)\n        \n        val_pearsonr = pearsonr(self.y_val, y_hat)[0]\n\n        print(f\"val_pearsonr: {val_pearsonr:.4f}\\n\")\n        logs[\"val_pearsonr\"] = val_pearsonr","metadata":{"execution":{"iopub.status.busy":"2022-06-16T00:23:35.848806Z","iopub.execute_input":"2022-06-16T00:23:35.849125Z","iopub.status.idle":"2022-06-16T00:23:35.856801Z","shell.execute_reply.started":"2022-06-16T00:23:35.849079Z","shell.execute_reply":"2022-06-16T00:23:35.855623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_folds(train, config):\n    \n    oof = np.zeros(config.num_folds)\n    \n    skf = StratifiedKFold(n_splits=config.num_folds, \n                      shuffle=True,\n                      random_state=config.seed)\n    \n    train['score_map'] = train['score'].map({0.00: 0, 0.25: 1, 0.50: 2, 0.75: 3, 1.00: 4})\n    for fold, (train_idx, val_idx) in enumerate(skf.split(train, train[\"score_map\"])):\n        print(\"*\" * 25)\n        print(f\"Training fold: {fold+1}\")\n\n        K.clear_session()\n        tf.tpu.experimental.initialize_tpu_system(tpu)\n        train_df = train.loc[train_idx].reset_index(drop=True)\n        val_df = train.loc[val_idx].reset_index(drop=True)\n        \n        \n        train_set = prepare_for_model(train_df, train = True)\n        val_set = prepare_for_model(val_df, train = False)\n\n        checkpoint = tf.keras.callbacks.ModelCheckpoint(f'model-{fold+1}.h5',\n                                                        monitor='val_loss',\n                                                        mode='min',\n                                                        save_best_only=True,\n                                                        save_weights_only=True,\n                                                        save_freq='epoch',\n                                                        verbose=1)\n        \n        early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n                                                          mode='min',\n                                                          patience=5,\n                                                          verbose=1)\n        \n\n        metric = Pearsonr(val_set, val_df[\"y\"].tolist())\n        \n        model = createBERT(config)\n        history = model.fit(\n                        train_set,\n                        validation_data=val_set,\n                        epochs = 1,\n#                         epochs=config.epochs,\n                        callbacks=[checkpoint, \n                                   early_stopping,\n                                  metric],\n                        verbose=1\n                    )\n        \n#         import pdb; pdb.set_trace()\n        model.load_weights(f'model-{fold+1}.h5')\n        import pdb; pdb.set_trace()        \n        \n        logits = model.predict(val_set, batch_size = config.batch_size).reshape(-1)\n        \n        y_hat = tf.math.sigmoid(logits)\n        \n        y_hat = coral.cumprobs_to_label(y_hat, threshold = 0.5)\n        \n        performance = pearsonr(y_hat, val_df[\"y\"].tolist())[0]\n        \n        oof[fold] = performance\n        del model\n        gc.collect()\n        print(f\"PearsonR: {performance}\")\n    \n    \n    return oof","metadata":{"execution":{"iopub.status.busy":"2022-06-16T01:06:22.39314Z","iopub.execute_input":"2022-06-16T01:06:22.394067Z","iopub.status.idle":"2022-06-16T01:06:22.412096Z","shell.execute_reply.started":"2022-06-16T01:06:22.394029Z","shell.execute_reply":"2022-06-16T01:06:22.410953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config = Config()\nbert_results = train_folds(train, config)","metadata":{"execution":{"iopub.status.busy":"2022-06-16T01:06:22.915945Z","iopub.execute_input":"2022-06-16T01:06:22.916244Z","iopub.status.idle":"2022-06-16T01:18:22.348393Z","shell.execute_reply.started":"2022-06-16T01:06:22.916212Z","shell.execute_reply":"2022-06-16T01:18:22.347032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Roberta with Bi-LSTM: np.mean(np.array([0.80018084, 0.80536421, 0.80386591, 0.81383098, 0.81148292]))\n# ROberta + Linear: np.mean(np.array([0.8099835003914698, 0.789178461208096, 0.8024664431203516, 0.8100770823958504, 0.8085313492150906]))","metadata":{"execution":{"iopub.status.busy":"2022-06-16T00:37:54.260606Z","iopub.status.idle":"2022-06-16T00:37:54.261011Z","shell.execute_reply.started":"2022-06-16T00:37:54.260812Z","shell.execute_reply":"2022-06-16T00:37:54.260845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bert_results","metadata":{"execution":{"iopub.status.busy":"2022-06-16T00:37:54.263161Z","iopub.status.idle":"2022-06-16T00:37:54.263514Z","shell.execute_reply.started":"2022-06-16T00:37:54.263336Z","shell.execute_reply":"2022-06-16T00:37:54.263359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.mean(bert_results)","metadata":{"execution":{"iopub.status.busy":"2022-06-16T00:37:54.265345Z","iopub.status.idle":"2022-06-16T00:37:54.2659Z","shell.execute_reply.started":"2022-06-16T00:37:54.265669Z","shell.execute_reply":"2022-06-16T00:37:54.265688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}