{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n    \n\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nimport tqdm\nimport random\nfrom tensorflow.keras import backend as K\nfrom sklearn.model_selection import StratifiedKFold\nfrom scipy.stats import pearsonr\n\nfrom transformers import AutoTokenizer, TFAutoModel\nimport transformers\n\nfrom datasets import Dataset\nimport tensorflow_probability as tfp\nfrom tensorflow.python.ops import array_ops\nfrom tensorflow.python.ops import math_ops\nimport gc\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-15T15:31:53.727679Z","iopub.execute_input":"2022-06-15T15:31:53.728004Z","iopub.status.idle":"2022-06-15T15:32:02.951443Z","shell.execute_reply.started":"2022-06-15T15:31:53.727926Z","shell.execute_reply":"2022-06-15T15:32:02.950691Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"#Setting up a TPU\ntry:\n    # TPU config\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n    auto = tf.data.experimental.AUTOTUNE\n    replicas = strategy.num_replicas_in_sync\n    print(f'TPU: {tpu.master()}')\nexcept:\n    strategy = tf.distribute.get_strategy()\n    auto = tf.data.experimental.AUTOTUNE\n    replicas = strategy.num_replicas_in_sync\n\n# XLA acceleartion\ntf.config.optimizer.set_jit(True)\nprint(f'Replicas: {replicas}')","metadata":{"execution":{"iopub.status.busy":"2022-06-15T15:32:02.952819Z","iopub.execute_input":"2022-06-15T15:32:02.953045Z","iopub.status.idle":"2022-06-15T15:32:02.963238Z","shell.execute_reply.started":"2022-06-15T15:32:02.953017Z","shell.execute_reply":"2022-06-15T15:32:02.962663Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# BertLegal (Inspired by: https://www.kaggle.com/code/mohamadmerchant/us-phrase-matching-tf-keras-train-tpu)\n","metadata":{}},{"cell_type":"code","source":"# Configuration setup for BERT\nclass Config():\n    seed = 69\n    epochs = 40\n    num_folds = 5\n    max_length = 412\n    batch_size = 128\n    # THIS LEARNING RATE IS FOR THE TRANSFORMER\n    lr1 = 1e-10\n    \n    # THIS LEARNING RATE IS FOR THE OUTPUT\n    lr2 = 1e-4\n    base = \"anferico/bert-for-patents\"\n    shuffle = True\n    \n    def __init__(self, **kwargs):\n        for k, v in kwargs.items():\n            setattr(self, k, v)\n            \n#Setting a constant seed\ndef seed_everything(seed=69):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n    \nseed_everything(seed=69)\nconfig = Config()","metadata":{"execution":{"iopub.status.busy":"2022-06-15T15:32:02.964410Z","iopub.execute_input":"2022-06-15T15:32:02.964764Z","iopub.status.idle":"2022-06-15T15:32:02.977817Z","shell.execute_reply.started":"2022-06-15T15:32:02.964735Z","shell.execute_reply":"2022-06-15T15:32:02.977242Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"#Initializing the tokenizer for BERT\ntokenizer = AutoTokenizer.from_pretrained(config.base, special_tokens=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-15T15:32:02.979419Z","iopub.execute_input":"2022-06-15T15:32:02.979933Z","iopub.status.idle":"2022-06-15T15:32:04.036185Z","shell.execute_reply.started":"2022-06-15T15:32:02.979901Z","shell.execute_reply":"2022-06-15T15:32:04.035410Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"#Creating a dictionary for each context code\ncodes = pd.read_csv(\"../input/cpc-codes/titles.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-06-15T15:32:04.037220Z","iopub.execute_input":"2022-06-15T15:32:04.037441Z","iopub.status.idle":"2022-06-15T15:32:04.697940Z","shell.execute_reply.started":"2022-06-15T15:32:04.037416Z","shell.execute_reply":"2022-06-15T15:32:04.696769Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"#Creating a dictionary for each context code\nmapping = dict(zip(codes.code, codes.title))","metadata":{"execution":{"iopub.status.busy":"2022-06-15T15:32:04.699264Z","iopub.execute_input":"2022-06-15T15:32:04.699565Z","iopub.status.idle":"2022-06-15T15:32:04.854372Z","shell.execute_reply.started":"2022-06-15T15:32:04.699535Z","shell.execute_reply":"2022-06-15T15:32:04.853592Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def process_data(file_path):\n    file = pd.read_csv(f\"../input/us-patent-phrase-to-phrase-matching/{file_path}\")\n    \n    #Using dictionary to get the context code and the text associated with each code\n    file[\"context_text\"] = file[\"context\"].map(lambda code: mapping.get(code, \"\"))\n    #Creating a custom token for each tokenizer to hopefully get some deeper understanding of the text\n    file[\"section_context\"] = \"[\" + file.context.str[0] + \"]\"\n    # Creating the final input to bert\n    file[\"input\"] = file.section_context + \" \" + file.context_text.str.lower() + \" [SEP] \" + file.anchor.str.lower() + \" [SEP] \" + file.target.str.lower()\n    return file","metadata":{"execution":{"iopub.status.busy":"2022-06-15T15:32:04.855438Z","iopub.execute_input":"2022-06-15T15:32:04.855636Z","iopub.status.idle":"2022-06-15T15:32:04.867343Z","shell.execute_reply.started":"2022-06-15T15:32:04.855612Z","shell.execute_reply":"2022-06-15T15:32:04.866399Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train = process_data(\"train.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-06-15T15:32:04.868272Z","iopub.execute_input":"2022-06-15T15:32:04.868484Z","iopub.status.idle":"2022-06-15T15:32:05.034394Z","shell.execute_reply.started":"2022-06-15T15:32:04.868459Z","shell.execute_reply":"2022-06-15T15:32:05.033875Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Feeding in the custom tokens to BERT\ncontext_tokens = list(train.section_context.unique())\ntokenizer.add_special_tokens({'additional_special_tokens': context_tokens})","metadata":{"execution":{"iopub.status.busy":"2022-06-15T15:32:05.035510Z","iopub.execute_input":"2022-06-15T15:32:05.036198Z","iopub.status.idle":"2022-06-15T15:32:05.049961Z","shell.execute_reply.started":"2022-06-15T15:32:05.036159Z","shell.execute_reply":"2022-06-15T15:32:05.049242Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"test = process_data(\"test.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-06-15T15:32:05.052895Z","iopub.execute_input":"2022-06-15T15:32:05.053118Z","iopub.status.idle":"2022-06-15T15:32:05.066424Z","shell.execute_reply.started":"2022-06-15T15:32:05.053055Z","shell.execute_reply":"2022-06-15T15:32:05.065657Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Preparing data to model using Tensorflow data api\n#NOTE: Honestly quite slow... could be much faster using data_collators, but TPUs don't support them\ndef prepare_for_model(data, shuffle=True):\n    inputs = tokenizer(list(data[\"input\"].values), padding = \"max_length\", max_length = config.max_length, truncation = True)\n    \n    dataset = \"\"\n    if shuffle:\n        dataset = tf.data.Dataset.from_tensor_slices((inputs.data, data['score'].tolist())).shuffle(1024).batch(config.batch_size).prefetch(tf.data.AUTOTUNE)\n    else:\n        dataset = tf.data.Dataset.from_tensor_slices((inputs.data, data['score'].tolist())).batch(config.batch_size).prefetch(tf.data.AUTOTUNE)\n    \n    \n    return dataset","metadata":{"execution":{"iopub.status.busy":"2022-06-15T15:32:05.067512Z","iopub.execute_input":"2022-06-15T15:32:05.067835Z","iopub.status.idle":"2022-06-15T15:32:05.075254Z","shell.execute_reply.started":"2022-06-15T15:32:05.067805Z","shell.execute_reply":"2022-06-15T15:32:05.074526Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Custom Loss function (Pearson Correlation implementation: Also the metric for the competition!!!)\ndef correlationLoss(y_actual, y_pred, axis=-2):\n    \"\"\"Metric returning the Pearson correlation coefficient of two tensors over some axis, default -2.\"\"\"\n#     import pdb; pdb.set_trace()\n    #Ignore the bad variables names here I didn't write this code\n    x = tf.convert_to_tensor(y_actual)\n    y = math_ops.cast(y_pred, x.dtype)\n    n = tf.cast(tf.shape(x)[axis], x.dtype)\n    xsum = tf.reduce_sum(x, axis=axis)\n    ysum = tf.reduce_sum(y, axis=axis)\n    xmean = xsum / n\n    ymean = ysum / n\n    xvar = tf.reduce_sum( tf.math.squared_difference(x, xmean), axis=axis)\n    yvar = tf.reduce_sum( tf.math.squared_difference(y, ymean), axis=axis)\n    cov = tf.reduce_sum( (x - xmean) * (y - ymean), axis=axis)\n    corr = cov / tf.sqrt(xvar * yvar)\n    return tf.constant(1.0, dtype=x.dtype) - corr","metadata":{"execution":{"iopub.status.busy":"2022-06-15T15:32:05.076621Z","iopub.execute_input":"2022-06-15T15:32:05.076923Z","iopub.status.idle":"2022-06-15T15:32:05.089405Z","shell.execute_reply.started":"2022-06-15T15:32:05.076888Z","shell.execute_reply":"2022-06-15T15:32:05.088603Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"#Creating BERT\ndef createBERT(config):\n    #For TPUs. If you don't have a TPU, remove strategy.scope!\n    with strategy.scope():\n        \n        steps_per_epoch = 36473 // config.batch_size\n        \n        clr1 = tfa.optimizers.CyclicalLearningRate(initial_learning_rate=config.lr1 / 10,\n            maximal_learning_rate=config.lr1,\n            scale_fn=lambda x: 1/(2.**(x-1)),\n            step_size=2 * steps_per_epoch\n        )\n        \n        clr2 = tfa.optimizers.CyclicalLearningRate(initial_learning_rate=config.lr2 / 10,\n            maximal_learning_rate=config.lr2,\n            scale_fn=lambda x: 1/(2.**(x-1)),\n            step_size=2 * steps_per_epoch\n        )\n        \n        \n        input_ids = tf.keras.layers.Input(\n            shape=(config.max_length,), dtype=tf.int32, name=\"input_ids\"\n        )\n\n        attention_masks = tf.keras.layers.Input(\n            shape=(config.max_length,), dtype=tf.int32, name=\"attention_mask\"\n        )\n        \n        token_type_ids = tf.keras.layers.Input(\n            shape=(config.max_length,), dtype=tf.int32, name=\"token_type_ids\"\n        )\n\n        base_model = transformers.TFAutoModel.from_pretrained(config.base, from_pt=True)\n\n        base_model_output = base_model(\n            input_ids, attention_mask=attention_masks, token_type_ids=token_type_ids\n        )\n\n        last_hidden_state = base_model_output.last_hidden_state[:, 0, :]\n        \n        dropout = tf.keras.layers.Dropout(base_model.config.hidden_dropout_prob)(last_hidden_state)\n        \n        dense = tf.keras.layers.Dense(base_model.config.hidden_size, activation = \"tanh\")(dropout)\n        \n        dropout = tf.keras.layers.Dropout(base_model.config.hidden_dropout_prob)(dense)\n        \n        model_output = tf.keras.layers.Dense(1, activation = \"sigmoid\")(dropout)\n        \n        model = tf.keras.models.Model(\n            inputs=[input_ids, attention_masks, token_type_ids], outputs=model_output\n        )\n        \n#         optimizers = [\n#             tfa.optimizers.AdamW(weight_decay=config.weight_decay, learning_rate=config.lr1),\n#             tfa.optimizers.AdamW(weight_decay=config.weight_decay, learning_rate=config.lr2)\n#         ]\n        \n        optimizers = [\n            tf.keras.optimizers.Adam(learning_rate=clr1),\n            tf.keras.optimizers.Adam(learning_rate=clr2)\n        ]\n        \n        optimizers_and_layers = [(optimizers[0], model.layers[0:4]), (optimizers[1], model.layers[3:])]\n        optimizer = tfa.optimizers.MultiOptimizer(optimizers_and_layers)\n        \n        \n#         loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits = False)\n        loss_fn = correlationLoss\n\n        model.compile(\n            optimizer = optimizer,\n            loss=loss_fn\n        )\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-06-15T15:32:05.090984Z","iopub.execute_input":"2022-06-15T15:32:05.091253Z","iopub.status.idle":"2022-06-15T15:32:05.108964Z","shell.execute_reply.started":"2022-06-15T15:32:05.091216Z","shell.execute_reply":"2022-06-15T15:32:05.108499Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-15T15:37:21.228640Z","iopub.execute_input":"2022-06-15T15:37:21.229000Z","iopub.status.idle":"2022-06-15T15:37:21.245761Z","shell.execute_reply.started":"2022-06-15T15:37:21.228973Z","shell.execute_reply":"2022-06-15T15:37:21.245035Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def train_folds(train, config):\n    \n    oof = np.zeros(config.num_folds)\n    \n    skf = StratifiedKFold(n_splits=config.num_folds, \n                      shuffle=True,\n                      random_state=config.seed)\n\n    #Break training set into multiple folds\n    train['score_map'] = train['score'].map({0.00: 0, 0.25: 1, 0.50: 2, 0.75: 3, 1.00: 4})\n    for fold, (train_idx, val_idx) in enumerate(skf.split(train, train[\"score_map\"])):\n        print(\"*\" * 25)\n        print(f\"Training fold: {fold+1}\")\n\n        # Clearing TPU and freeing memory\n        K.clear_session()\n        #Remove this if no TPU\n        tf.tpu.experimental.initialize_tpu_system(tpu)\n        train_df = train.loc[train_idx].reset_index(drop=True)\n        val_df = train.loc[val_idx].reset_index(drop=True)\n        \n        \n        train_set = prepare_for_model(train_df)\n        val_set = prepare_for_model(val_df, shuffle = False)\n\n        checkpoint = tf.keras.callbacks.ModelCheckpoint(f'model-{fold+1}.h5',\n                                                        monitor='val_loss',\n                                                        mode='min',\n                                                        save_best_only=True,\n                                                        save_weights_only=True,\n                                                        save_freq='epoch',\n                                                        verbose=1)\n        \n        early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n                                                          mode='min',\n                                                          patience=5,\n                                                          verbose=1)\n        \n\n        \n        model = createBERT(config)\n        history = model.fit(\n                        train_set,\n                        validation_data=val_set,\n                        epochs=config.epochs,\n                        callbacks=[checkpoint, \n                                   early_stopping],\n                        verbose=1\n                    )\n        \n#         import pdb; pdb.set_trace()\n        model.load_weights(f'model-{fold+1}.h5')\n        y_hat = model.predict(val_set, batch_size = config.batch_size).reshape(-1)\n        \n        #Using the metric for evaluation\n        performance = pearsonr(y_hat, val_df[\"score\"].tolist())[0]\n        oof[fold] = performance\n        #Freeing up memory\n        del model\n        gc.collect()\n        print(f\"PearsonR: {performance}\")\n    \n    \n    return oof","metadata":{"execution":{"iopub.status.busy":"2022-06-15T15:39:57.726408Z","iopub.execute_input":"2022-06-15T15:39:57.726840Z","iopub.status.idle":"2022-06-15T15:39:57.733729Z","shell.execute_reply.started":"2022-06-15T15:39:57.726803Z","shell.execute_reply":"2022-06-15T15:39:57.733260Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"train = process_data(\"train.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-06-15T15:45:55.628000Z","iopub.execute_input":"2022-06-15T15:45:55.628296Z","iopub.status.idle":"2022-06-15T15:45:55.860136Z","shell.execute_reply.started":"2022-06-15T15:45:55.628262Z","shell.execute_reply":"2022-06-15T15:45:55.859134Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"config = Config()\noof = train_folds(train, config)","metadata":{"execution":{"iopub.status.busy":"2022-06-15T15:45:58.375782Z","iopub.execute_input":"2022-06-15T15:45:58.376133Z","iopub.status.idle":"2022-06-15T15:45:58.392035Z","shell.execute_reply.started":"2022-06-15T15:45:58.376107Z","shell.execute_reply":"2022-06-15T15:45:58.391482Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"config = Config()\nbert_results = train_folds(train, config)","metadata":{"execution":{"iopub.status.busy":"2022-06-15T15:32:05.682414Z","iopub.status.idle":"2022-06-15T15:32:05.682914Z","shell.execute_reply.started":"2022-06-15T15:32:05.682652Z","shell.execute_reply":"2022-06-15T15:32:05.682674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bert_results","metadata":{"execution":{"iopub.status.busy":"2022-06-15T15:32:05.686628Z","iopub.status.idle":"2022-06-15T15:32:05.686968Z","shell.execute_reply.started":"2022-06-15T15:32:05.686786Z","shell.execute_reply":"2022-06-15T15:32:05.686807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.mean(bert_results)","metadata":{"execution":{"iopub.status.busy":"2022-06-15T15:32:05.687745Z","iopub.status.idle":"2022-06-15T15:32:05.688062Z","shell.execute_reply.started":"2022-06-15T15:32:05.687886Z","shell.execute_reply":"2022-06-15T15:32:05.687908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}