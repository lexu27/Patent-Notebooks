{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n    \n\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nimport tqdm\nimport random\nfrom tensorflow.keras import backend as K\nfrom sklearn.model_selection import StratifiedKFold\nfrom scipy.stats import pearsonr\n\nfrom transformers import AutoTokenizer, TFAutoModel\nimport transformers\n\nfrom datasets import Dataset\nimport tensorflow_probability as tfp\nfrom tensorflow.python.ops import array_ops\nfrom tensorflow.python.ops import math_ops\nimport gc\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-15T16:44:10.875734Z","iopub.execute_input":"2022-06-15T16:44:10.876379Z","iopub.status.idle":"2022-06-15T16:44:21.031586Z","shell.execute_reply.started":"2022-06-15T16:44:10.876265Z","shell.execute_reply":"2022-06-15T16:44:21.030593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inferences = None","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2022-06-15T16:44:21.03316Z","iopub.execute_input":"2022-06-15T16:44:21.033833Z","iopub.status.idle":"2022-06-15T16:44:21.038226Z","shell.execute_reply.started":"2022-06-15T16:44:21.033794Z","shell.execute_reply":"2022-06-15T16:44:21.03707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"codes = pd.read_csv(\"../input/cpc-codes/titles.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:44:21.039508Z","iopub.execute_input":"2022-06-15T16:44:21.040177Z","iopub.status.idle":"2022-06-15T16:44:21.766296Z","shell.execute_reply.started":"2022-06-15T16:44:21.040135Z","shell.execute_reply":"2022-06-15T16:44:21.764983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mapping = dict(zip(codes.code, codes.title))","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:44:21.768578Z","iopub.execute_input":"2022-06-15T16:44:21.768913Z","iopub.status.idle":"2022-06-15T16:44:21.913706Z","shell.execute_reply.started":"2022-06-15T16:44:21.768866Z","shell.execute_reply":"2022-06-15T16:44:21.91284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_tokenizer(config):\n    return AutoTokenizer.from_pretrained(config.base, special_tokens=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:44:21.914876Z","iopub.execute_input":"2022-06-15T16:44:21.915704Z","iopub.status.idle":"2022-06-15T16:44:21.92051Z","shell.execute_reply.started":"2022-06-15T16:44:21.915667Z","shell.execute_reply":"2022-06-15T16:44:21.919528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Slow\n# def prepare_for_inference(data, tokenizer, config):\n#     inputs = tokenizer(list(data[\"input\"].values), padding = \"max_length\", max_length = config.max_length, truncation = True)\n#     dataset = tf.data.Dataset.from_tensor_slices(inputs.data).batch(config.batch_size).prefetch(tf.data.AUTOTUNE)\n    \n#     return dataset","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:44:21.9222Z","iopub.execute_input":"2022-06-15T16:44:21.923055Z","iopub.status.idle":"2022-06-15T16:44:21.929213Z","shell.execute_reply.started":"2022-06-15T16:44:21.923015Z","shell.execute_reply":"2022-06-15T16:44:21.928461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import DefaultDataCollator\nfrom datasets import Dataset\n\ndef prepare_for_inference(data, tokenizer, config):\n    data_collator = DefaultDataCollator(return_tensors=\"tf\")\n    dataset = Dataset.from_pandas(data)\n    dataset = dataset.map(lambda x: tokenizer(x[\"input\"], padding=\"max_length\", truncation=True, max_length = config.max_length), batched=True, num_proc=8)\n    dataset = dataset.to_tf_dataset(\n        columns=[\"attention_mask\", \"input_ids\", \"token_type_ids\"],\n        shuffle=False,\n        collate_fn=data_collator,\n        batch_size=config.batch_size,\n    )\n    \n    return dataset","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:44:21.932339Z","iopub.execute_input":"2022-06-15T16:44:21.933007Z","iopub.status.idle":"2022-06-15T16:44:21.958715Z","shell.execute_reply.started":"2022-06-15T16:44:21.932975Z","shell.execute_reply":"2022-06-15T16:44:21.95796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_inferences(model, test_data, config, name, num):\n    global inferences\n    for fold in tqdm.tqdm(range(num)):\n        model.load_weights(f\"../input/patent-weights/Patent-Weights/{name}/model-{fold + 1}.h5\")\n        if inferences is not None:\n            inferences = np.vstack((inferences, model.predict(test_data).reshape(-1)))\n        else:\n            inferences = model.predict(test_data, batch_size = config.batch_size).reshape(-1)\n        print(f\"{model} {fold + 1} inferences: {inferences[-1]}\")","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:44:21.960277Z","iopub.execute_input":"2022-06-15T16:44:21.960671Z","iopub.status.idle":"2022-06-15T16:44:21.967452Z","shell.execute_reply.started":"2022-06-15T16:44:21.960627Z","shell.execute_reply":"2022-06-15T16:44:21.966343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def correlationLoss(y_actual, y_pred, axis=-2):\n    \"\"\"Metric returning the Pearson correlation coefficient of two tensors over some axis, default -2.\"\"\"\n#     import pdb; pdb.set_trace()\n    #Ignore the bad variables names here I didn't write this code\n    x = tf.convert_to_tensor(y_actual)\n    y = math_ops.cast(y_pred, x.dtype)\n    n = tf.cast(tf.shape(x)[axis], x.dtype)\n    xsum = tf.reduce_sum(x, axis=axis)\n    ysum = tf.reduce_sum(y, axis=axis)\n    xmean = xsum / n\n    ymean = ysum / n\n    xvar = tf.reduce_sum( tf.math.squared_difference(x, xmean), axis=axis)\n    yvar = tf.reduce_sum( tf.math.squared_difference(y, ymean), axis=axis)\n    cov = tf.reduce_sum( (x - xmean) * (y - ymean), axis=axis)\n    corr = cov / tf.sqrt(xvar * yvar)\n    return tf.constant(1.0, dtype=x.dtype) - corr","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:44:21.969338Z","iopub.execute_input":"2022-06-15T16:44:21.969815Z","iopub.status.idle":"2022-06-15T16:44:21.980412Z","shell.execute_reply.started":"2022-06-15T16:44:21.969774Z","shell.execute_reply":"2022-06-15T16:44:21.979299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Electra Inferencing","metadata":{}},{"cell_type":"code","source":"class ElectraConfig():\n    seed = 69\n    epochs = 40\n    num_folds = 5\n    max_length = 412\n    batch_size = 256\n    # THIS LEARNING RATE IS FOR THE TRANSFORMER\n    lr1 = 1e-6\n    \n    # THIS LEARNING RATE IS FOR THE OUTPUT\n    lr2 = 1e-4\n    base = \"../input/initialization/electra-base-sst2\"\n#     base = \"google/electra-base-generator\"\n#     base = \"google/electra-base-discriminator\"\n    shuffle = True\n    \n    def __init__(self, **kwargs):\n        for k, v in kwargs.items():\n            setattr(self, k, v)\n            \ndef seed_everything(seed=69):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n\nelectra_config = ElectraConfig()\nseed_everything(electra_config.seed)\ndel seed_everything\ndel ElectraConfig","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:44:21.984805Z","iopub.execute_input":"2022-06-15T16:44:21.985374Z","iopub.status.idle":"2022-06-15T16:44:21.994077Z","shell.execute_reply.started":"2022-06-15T16:44:21.985336Z","shell.execute_reply":"2022-06-15T16:44:21.99328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"electra_tokenizer = get_tokenizer(electra_config)","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:44:21.99576Z","iopub.execute_input":"2022-06-15T16:44:21.996632Z","iopub.status.idle":"2022-06-15T16:44:22.050764Z","shell.execute_reply.started":"2022-06-15T16:44:21.99659Z","shell.execute_reply":"2022-06-15T16:44:22.049993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def electra_process_data(file_path):\n    file = pd.read_csv(f\"../input/us-patent-phrase-to-phrase-matching/{file_path}\")\n    file[\"context_text\"] = file[\"context\"].map(lambda code: mapping.get(code, \"\"))\n    file[\"section_context\"] = \"[\" + file.context.str[0] + \"]\"\n    file[\"input\"] = file.section_context + \" \" + file.context_text.str.lower() + \" [SEP] \" + file.anchor.str.lower() + \" [SEP] \" + file.target.str.lower()\n    return file","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:44:22.052221Z","iopub.execute_input":"2022-06-15T16:44:22.05257Z","iopub.status.idle":"2022-06-15T16:44:22.058771Z","shell.execute_reply.started":"2022-06-15T16:44:22.052536Z","shell.execute_reply":"2022-06-15T16:44:22.057823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"electra_train = electra_process_data(\"train.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:44:22.06046Z","iopub.execute_input":"2022-06-15T16:44:22.061002Z","iopub.status.idle":"2022-06-15T16:44:22.264952Z","shell.execute_reply.started":"2022-06-15T16:44:22.060956Z","shell.execute_reply":"2022-06-15T16:44:22.26419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"electra_train.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:44:22.266073Z","iopub.execute_input":"2022-06-15T16:44:22.266925Z","iopub.status.idle":"2022-06-15T16:44:22.286456Z","shell.execute_reply.started":"2022-06-15T16:44:22.266867Z","shell.execute_reply":"2022-06-15T16:44:22.285608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"context_tokens = list(electra_train.section_context.unique())\nelectra_tokenizer.add_special_tokens({'additional_special_tokens': context_tokens})","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:44:22.287716Z","iopub.execute_input":"2022-06-15T16:44:22.288151Z","iopub.status.idle":"2022-06-15T16:44:22.29887Z","shell.execute_reply.started":"2022-06-15T16:44:22.288113Z","shell.execute_reply":"2022-06-15T16:44:22.297941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del electra_train, context_tokens","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:44:22.300391Z","iopub.execute_input":"2022-06-15T16:44:22.30117Z","iopub.status.idle":"2022-06-15T16:44:22.304987Z","shell.execute_reply.started":"2022-06-15T16:44:22.301108Z","shell.execute_reply":"2022-06-15T16:44:22.304265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"electra_test = electra_process_data(\"test.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:44:22.306344Z","iopub.execute_input":"2022-06-15T16:44:22.306911Z","iopub.status.idle":"2022-06-15T16:44:22.325619Z","shell.execute_reply.started":"2022-06-15T16:44:22.30686Z","shell.execute_reply":"2022-06-15T16:44:22.324939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del electra_process_data","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:44:22.326835Z","iopub.execute_input":"2022-06-15T16:44:22.32726Z","iopub.status.idle":"2022-06-15T16:44:22.333521Z","shell.execute_reply.started":"2022-06-15T16:44:22.327194Z","shell.execute_reply":"2022-06-15T16:44:22.332704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"electra_test = prepare_for_inference(electra_test, electra_tokenizer, electra_config)","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:44:22.335115Z","iopub.execute_input":"2022-06-15T16:44:22.335516Z","iopub.status.idle":"2022-06-15T16:44:28.754544Z","shell.execute_reply.started":"2022-06-15T16:44:22.335459Z","shell.execute_reply":"2022-06-15T16:44:28.753641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del electra_tokenizer","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:44:28.75589Z","iopub.execute_input":"2022-06-15T16:44:28.756867Z","iopub.status.idle":"2022-06-15T16:44:28.767696Z","shell.execute_reply.started":"2022-06-15T16:44:28.756825Z","shell.execute_reply":"2022-06-15T16:44:28.766848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def createElectra(config):\n    steps_per_epoch = 36473 // config.batch_size\n\n    clr1 = tfa.optimizers.CyclicalLearningRate(initial_learning_rate=config.lr1 / 10,\n        maximal_learning_rate=config.lr1,\n        scale_fn=lambda x: 1/(2.**(x-1)),\n        step_size=2 * steps_per_epoch\n    )\n\n    clr2 = tfa.optimizers.CyclicalLearningRate(initial_learning_rate=config.lr2 / 10,\n        maximal_learning_rate=config.lr2,\n        scale_fn=lambda x: 1/(2.**(x-1)),\n        step_size=2 * steps_per_epoch\n    )\n\n\n    input_ids = tf.keras.layers.Input(\n        shape=(config.max_length,), dtype=tf.int32, name=\"input_ids\"\n    )\n\n    attention_masks = tf.keras.layers.Input(\n        shape=(config.max_length,), dtype=tf.int32, name=\"attention_mask\"\n    )\n\n    token_type_ids = tf.keras.layers.Input(\n        shape=(config.max_length,), dtype=tf.int32, name=\"token_type_ids\"\n    )\n\n    base_model = transformers.TFAutoModel.from_pretrained(config.base)\n\n    base_model_output = base_model(\n        input_ids, attention_mask=attention_masks, token_type_ids=token_type_ids\n    )\n\n    #Cls token from output\n    last_hidden_state = base_model_output.last_hidden_state[:, 0, :]\n\n    dropout = tf.keras.layers.Dropout(base_model.config.hidden_dropout_prob)(last_hidden_state)\n\n    dense = tf.keras.layers.Dense(base_model.config.hidden_size, activation = \"gelu\")(dropout)\n\n    dropout = tf.keras.layers.Dropout(base_model.config.hidden_dropout_prob)(dense)\n\n    model_output = tf.keras.layers.Dense(1, activation = \"sigmoid\")(dropout)\n\n    model = tf.keras.models.Model(\n        inputs=[input_ids, attention_masks, token_type_ids], outputs=model_output\n    )\n\n#         optimizers = [\n#             tfa.optimizers.AdamW(weight_decay=config.weight_decay, learning_rate=config.lr1),\n#             tfa.optimizers.AdamW(weight_decay=config.weight_decay, learning_rate=config.lr2)\n#         ]\n\n    optimizers = [\n        tf.keras.optimizers.Adam(learning_rate=clr1),\n        tf.keras.optimizers.Adam(learning_rate=clr2)\n    ]\n\n    optimizers_and_layers = [(optimizers[0], model.layers[0:4]), (optimizers[1], model.layers[3:])]\n    optimizer = tfa.optimizers.MultiOptimizer(optimizers_and_layers)\n\n\n#         loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits = False)\n    loss_fn = correlationLoss\n\n    model.compile(\n        optimizer = optimizer,\n        loss=loss_fn,\n        steps_per_execution=steps_per_epoch\n    )\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:44:28.769411Z","iopub.execute_input":"2022-06-15T16:44:28.769848Z","iopub.status.idle":"2022-06-15T16:44:28.785127Z","shell.execute_reply.started":"2022-06-15T16:44:28.769811Z","shell.execute_reply":"2022-06-15T16:44:28.784229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Electra = createElectra(electra_config)","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:44:28.786834Z","iopub.execute_input":"2022-06-15T16:44:28.787536Z","iopub.status.idle":"2022-06-15T16:44:41.960976Z","shell.execute_reply.started":"2022-06-15T16:44:28.787498Z","shell.execute_reply":"2022-06-15T16:44:41.960193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del createElectra","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:44:41.962349Z","iopub.execute_input":"2022-06-15T16:44:41.962912Z","iopub.status.idle":"2022-06-15T16:44:41.968581Z","shell.execute_reply.started":"2022-06-15T16:44:41.962884Z","shell.execute_reply":"2022-06-15T16:44:41.967809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_inferences(Electra, electra_test, electra_config, \"Electra\", 5)","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:44:41.969869Z","iopub.execute_input":"2022-06-15T16:44:41.970824Z","iopub.status.idle":"2022-06-15T16:45:10.965109Z","shell.execute_reply.started":"2022-06-15T16:44:41.970782Z","shell.execute_reply":"2022-06-15T16:45:10.962968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del Electra, electra_config, electra_test","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:45:10.96668Z","iopub.execute_input":"2022-06-15T16:45:10.967369Z","iopub.status.idle":"2022-06-15T16:45:10.973442Z","shell.execute_reply.started":"2022-06-15T16:45:10.967322Z","shell.execute_reply":"2022-06-15T16:45:10.972538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:45:10.975217Z","iopub.execute_input":"2022-06-15T16:45:10.975941Z","iopub.status.idle":"2022-06-15T16:45:11.37362Z","shell.execute_reply.started":"2022-06-15T16:45:10.975883Z","shell.execute_reply":"2022-06-15T16:45:11.372845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# BERT Inferencing","metadata":{}},{"cell_type":"code","source":"class BERTConfig():\n    seed = 69\n    epochs = 40\n    num_folds = 5\n    max_length = 412\n    batch_size = 128\n    # THIS LEARNING RATE IS FOR THE TRANSFORMER\n    lr1 = 1e-10\n    \n    # THIS LEARNING RATE IS FOR THE OUTPUT\n    lr2 = 1e-4\n    base = \"../input/initialization/bert-for-patents\"\n    shuffle = True\n    \n    def __init__(self, **kwargs):\n        for k, v in kwargs.items():\n            setattr(self, k, v)\n            \ndef seed_everything(seed=69):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n\nbert_config = BERTConfig()\nseed_everything(bert_config.seed)\ndel seed_everything\ndel BERTConfig","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:45:11.3752Z","iopub.execute_input":"2022-06-15T16:45:11.375554Z","iopub.status.idle":"2022-06-15T16:45:11.381094Z","shell.execute_reply.started":"2022-06-15T16:45:11.375519Z","shell.execute_reply":"2022-06-15T16:45:11.380307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bert_tokenizer = get_tokenizer(bert_config)","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:45:11.387208Z","iopub.execute_input":"2022-06-15T16:45:11.387925Z","iopub.status.idle":"2022-06-15T16:45:11.391902Z","shell.execute_reply.started":"2022-06-15T16:45:11.387882Z","shell.execute_reply":"2022-06-15T16:45:11.39097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def bert_process_data(file_path):\n    file = pd.read_csv(f\"../input/us-patent-phrase-to-phrase-matching/{file_path}\")\n    file[\"context_text\"] = file[\"context\"].map(lambda code: mapping.get(code, \"\"))\n    file[\"section_context\"] = \"[\" + file.context.str[0] + \"]\"\n    file[\"input\"] = file.section_context + \" \" + file.context_text.str.lower() + \" [SEP] \" + file.anchor.str.lower() + \" [SEP] \" + file.target.str.lower()\n    return file","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:45:11.393084Z","iopub.execute_input":"2022-06-15T16:45:11.393702Z","iopub.status.idle":"2022-06-15T16:45:11.400895Z","shell.execute_reply.started":"2022-06-15T16:45:11.393661Z","shell.execute_reply":"2022-06-15T16:45:11.40007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bert_train = bert_process_data(\"train.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:45:11.402142Z","iopub.execute_input":"2022-06-15T16:45:11.402594Z","iopub.status.idle":"2022-06-15T16:45:11.409031Z","shell.execute_reply.started":"2022-06-15T16:45:11.402556Z","shell.execute_reply":"2022-06-15T16:45:11.408181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"context_tokens = list(bert_train.section_context.unique())\nbert_tokenizer.add_special_tokens({'additional_special_tokens': context_tokens})","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:45:11.41016Z","iopub.execute_input":"2022-06-15T16:45:11.410553Z","iopub.status.idle":"2022-06-15T16:45:11.417302Z","shell.execute_reply.started":"2022-06-15T16:45:11.410516Z","shell.execute_reply":"2022-06-15T16:45:11.416464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del bert_train, context_tokens","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:45:11.418898Z","iopub.execute_input":"2022-06-15T16:45:11.419454Z","iopub.status.idle":"2022-06-15T16:45:11.425347Z","shell.execute_reply.started":"2022-06-15T16:45:11.419403Z","shell.execute_reply":"2022-06-15T16:45:11.424387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bert_test = bert_process_data(\"test.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:45:11.427002Z","iopub.execute_input":"2022-06-15T16:45:11.427588Z","iopub.status.idle":"2022-06-15T16:45:11.435542Z","shell.execute_reply.started":"2022-06-15T16:45:11.427548Z","shell.execute_reply":"2022-06-15T16:45:11.434635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del bert_process_data","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:45:11.436997Z","iopub.execute_input":"2022-06-15T16:45:11.437413Z","iopub.status.idle":"2022-06-15T16:45:11.444682Z","shell.execute_reply.started":"2022-06-15T16:45:11.437374Z","shell.execute_reply":"2022-06-15T16:45:11.443826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bert_test = prepare_for_inference(bert_test, bert_tokenizer, bert_config)","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:45:11.446128Z","iopub.execute_input":"2022-06-15T16:45:11.446539Z","iopub.status.idle":"2022-06-15T16:45:11.452993Z","shell.execute_reply.started":"2022-06-15T16:45:11.446502Z","shell.execute_reply":"2022-06-15T16:45:11.45219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del bert_tokenizer","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:45:11.454416Z","iopub.execute_input":"2022-06-15T16:45:11.454817Z","iopub.status.idle":"2022-06-15T16:45:11.461838Z","shell.execute_reply.started":"2022-06-15T16:45:11.454779Z","shell.execute_reply":"2022-06-15T16:45:11.460976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def createBERT(config):\n    steps_per_epoch = 36473 // config.batch_size\n\n    clr1 = tfa.optimizers.CyclicalLearningRate(initial_learning_rate=config.lr1 / 10,\n        maximal_learning_rate=config.lr1,\n        scale_fn=lambda x: 1/(2.**(x-1)),\n        step_size=2 * steps_per_epoch\n    )\n\n    clr2 = tfa.optimizers.CyclicalLearningRate(initial_learning_rate=config.lr2 / 10,\n        maximal_learning_rate=config.lr2,\n        scale_fn=lambda x: 1/(2.**(x-1)),\n        step_size=2 * steps_per_epoch\n    )\n\n\n    input_ids = tf.keras.layers.Input(\n        shape=(config.max_length,), dtype=tf.int32, name=\"input_ids\"\n    )\n\n    attention_masks = tf.keras.layers.Input(\n        shape=(config.max_length,), dtype=tf.int32, name=\"attention_mask\"\n    )\n\n    token_type_ids = tf.keras.layers.Input(\n        shape=(config.max_length,), dtype=tf.int32, name=\"token_type_ids\"\n    )\n\n    base_model = transformers.TFAutoModel.from_pretrained(config.base)\n\n    base_model_output = base_model(\n        input_ids, attention_mask=attention_masks, token_type_ids=token_type_ids\n    )\n\n    last_hidden_state = base_model_output.last_hidden_state[:, 0, :]\n\n    dropout = tf.keras.layers.Dropout(base_model.config.hidden_dropout_prob)(last_hidden_state)\n\n    dense = tf.keras.layers.Dense(base_model.config.hidden_size, activation = \"tanh\")(dropout)\n\n    dropout = tf.keras.layers.Dropout(base_model.config.hidden_dropout_prob)(dense)\n\n    model_output = tf.keras.layers.Dense(1, activation = \"sigmoid\")(dropout)\n\n    model = tf.keras.models.Model(\n        inputs=[input_ids, attention_masks, token_type_ids], outputs=model_output\n    )\n\n#         optimizers = [\n#             tfa.optimizers.AdamW(weight_decay=config.weight_decay, learning_rate=config.lr1),\n#             tfa.optimizers.AdamW(weight_decay=config.weight_decay, learning_rate=config.lr2)\n#         ]\n\n    optimizers = [\n        tf.keras.optimizers.Adam(learning_rate=clr1),\n        tf.keras.optimizers.Adam(learning_rate=clr2)\n    ]\n\n    optimizers_and_layers = [(optimizers[0], model.layers[0:4]), (optimizers[1], model.layers[3:])]\n    optimizer = tfa.optimizers.MultiOptimizer(optimizers_and_layers)\n\n\n#         loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits = False)\n    loss_fn = correlationLoss\n\n    model.compile(\n        optimizer = optimizer,\n        loss=loss_fn\n    )\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:45:11.463328Z","iopub.execute_input":"2022-06-15T16:45:11.463737Z","iopub.status.idle":"2022-06-15T16:45:11.471964Z","shell.execute_reply.started":"2022-06-15T16:45:11.463702Z","shell.execute_reply":"2022-06-15T16:45:11.471068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BERT = createBERT(bert_config)","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:45:11.473541Z","iopub.execute_input":"2022-06-15T16:45:11.47394Z","iopub.status.idle":"2022-06-15T16:45:11.483824Z","shell.execute_reply.started":"2022-06-15T16:45:11.473887Z","shell.execute_reply":"2022-06-15T16:45:11.482887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del createBERT","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:45:11.485207Z","iopub.execute_input":"2022-06-15T16:45:11.485856Z","iopub.status.idle":"2022-06-15T16:45:11.492802Z","shell.execute_reply.started":"2022-06-15T16:45:11.485815Z","shell.execute_reply":"2022-06-15T16:45:11.492014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_inferences(BERT, bert_test, bert_config, \"BERT\", 4)","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:45:11.494761Z","iopub.execute_input":"2022-06-15T16:45:11.495325Z","iopub.status.idle":"2022-06-15T16:45:11.501296Z","shell.execute_reply.started":"2022-06-15T16:45:11.49528Z","shell.execute_reply":"2022-06-15T16:45:11.500467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del BERT, bert_config, bert_test","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:45:11.502915Z","iopub.execute_input":"2022-06-15T16:45:11.503406Z","iopub.status.idle":"2022-06-15T16:45:11.509872Z","shell.execute_reply.started":"2022-06-15T16:45:11.503367Z","shell.execute_reply":"2022-06-15T16:45:11.509063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:45:11.511012Z","iopub.execute_input":"2022-06-15T16:45:11.512542Z","iopub.status.idle":"2022-06-15T16:45:11.518172Z","shell.execute_reply.started":"2022-06-15T16:45:11.5125Z","shell.execute_reply":"2022-06-15T16:45:11.517283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# XLNet Inferencing","metadata":{}},{"cell_type":"code","source":"class XLConfig():\n    seed = 69\n    epochs = 40\n    num_folds = 5\n    max_length = 412\n    batch_size = 128\n    # THIS LEARNING RATE IS FOR THE TRANSFORMER\n    lr1 = 1e-6\n    \n    # THIS LEARNING RATE IS FOR THE OUTPUT\n    lr2 = 2e-4\n    base = \"../input/initialization/xlnet-base-cased-STS-B\"\n    shuffle = True\n    \n    def __init__(self, **kwargs):\n        for k, v in kwargs.items():\n            setattr(self, k, v)\n            \ndef seed_everything(seed=69):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n\nXL_config = XLConfig()\nseed_everything(XL_config.seed)\ndel seed_everything\ndel XLConfig","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:45:11.519808Z","iopub.execute_input":"2022-06-15T16:45:11.520261Z","iopub.status.idle":"2022-06-15T16:45:11.52789Z","shell.execute_reply.started":"2022-06-15T16:45:11.520224Z","shell.execute_reply":"2022-06-15T16:45:11.527093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"XL_tokenizer = get_tokenizer(XL_config)","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:45:11.529445Z","iopub.execute_input":"2022-06-15T16:45:11.529877Z","iopub.status.idle":"2022-06-15T16:45:11.536002Z","shell.execute_reply.started":"2022-06-15T16:45:11.52984Z","shell.execute_reply":"2022-06-15T16:45:11.535068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def XL_process_data(file_path):\n    file = pd.read_csv(f\"../input/us-patent-phrase-to-phrase-matching/{file_path}\")\n    file[\"context_text\"] = file[\"context\"].map(lambda code: mapping.get(code, \"\"))\n    file[\"section_context\"] = \"<\" + file.context.str[0] + \">\"\n    file[\"input\"] = file.section_context + \" \" + file.context_text.str.lower() + \" <sep> \" + file.anchor.str.lower() + \" <sep> \" + file.target.str.lower()\n    return file","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:45:11.537605Z","iopub.execute_input":"2022-06-15T16:45:11.538098Z","iopub.status.idle":"2022-06-15T16:45:11.545105Z","shell.execute_reply.started":"2022-06-15T16:45:11.537984Z","shell.execute_reply":"2022-06-15T16:45:11.54427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"XL_train = XL_process_data(\"train.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:45:11.5463Z","iopub.execute_input":"2022-06-15T16:45:11.547074Z","iopub.status.idle":"2022-06-15T16:45:11.554053Z","shell.execute_reply.started":"2022-06-15T16:45:11.547035Z","shell.execute_reply":"2022-06-15T16:45:11.553183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"context_tokens = list(XL_train.section_context.unique())\nXL_tokenizer.add_special_tokens({'additional_special_tokens': context_tokens})","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:45:11.555285Z","iopub.execute_input":"2022-06-15T16:45:11.55593Z","iopub.status.idle":"2022-06-15T16:45:11.565523Z","shell.execute_reply.started":"2022-06-15T16:45:11.55589Z","shell.execute_reply":"2022-06-15T16:45:11.564388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del context_tokens","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:45:11.566744Z","iopub.execute_input":"2022-06-15T16:45:11.567346Z","iopub.status.idle":"2022-06-15T16:45:11.575167Z","shell.execute_reply.started":"2022-06-15T16:45:11.567305Z","shell.execute_reply":"2022-06-15T16:45:11.574085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del XL_train","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:45:11.57673Z","iopub.execute_input":"2022-06-15T16:45:11.577187Z","iopub.status.idle":"2022-06-15T16:45:11.584381Z","shell.execute_reply.started":"2022-06-15T16:45:11.577128Z","shell.execute_reply":"2022-06-15T16:45:11.583327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"XL_test = XL_process_data(\"test.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:45:11.58564Z","iopub.execute_input":"2022-06-15T16:45:11.585941Z","iopub.status.idle":"2022-06-15T16:45:11.594352Z","shell.execute_reply.started":"2022-06-15T16:45:11.585907Z","shell.execute_reply":"2022-06-15T16:45:11.593476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del XL_process_data","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:45:11.595269Z","iopub.execute_input":"2022-06-15T16:45:11.595549Z","iopub.status.idle":"2022-06-15T16:45:11.603575Z","shell.execute_reply.started":"2022-06-15T16:45:11.595525Z","shell.execute_reply":"2022-06-15T16:45:11.602637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"XL_test = prepare_for_inference(XL_test, XL_tokenizer, XL_config)","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:45:11.605101Z","iopub.execute_input":"2022-06-15T16:45:11.605618Z","iopub.status.idle":"2022-06-15T16:45:11.613013Z","shell.execute_reply.started":"2022-06-15T16:45:11.605578Z","shell.execute_reply":"2022-06-15T16:45:11.611957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del XL_tokenizer","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:45:11.614373Z","iopub.execute_input":"2022-06-15T16:45:11.61474Z","iopub.status.idle":"2022-06-15T16:45:11.622776Z","shell.execute_reply.started":"2022-06-15T16:45:11.614709Z","shell.execute_reply":"2022-06-15T16:45:11.621896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def createXL(config):\n    steps_per_epoch = 36473 // config.batch_size\n\n    clr1 = tfa.optimizers.CyclicalLearningRate(initial_learning_rate=config.lr1 / 10,\n        maximal_learning_rate=config.lr1,\n        scale_fn=lambda x: 1/(2.**(x-1)),\n        step_size=2 * steps_per_epoch\n    )\n\n    clr2 = tfa.optimizers.CyclicalLearningRate(initial_learning_rate=config.lr2 / 10,\n        maximal_learning_rate=config.lr2,\n        scale_fn=lambda x: 1/(2.**(x-1)),\n        step_size=2 * steps_per_epoch\n    )\n\n\n    input_ids = tf.keras.layers.Input(\n        shape=(config.max_length,), dtype=tf.int32, name=\"input_ids\"\n    )\n\n    attention_masks = tf.keras.layers.Input(\n        shape=(config.max_length,), dtype=tf.int32, name=\"attention_mask\"\n    )\n\n    token_type_ids = tf.keras.layers.Input(\n        shape=(config.max_length,), dtype=tf.int32, name=\"token_type_ids\"\n    )\n\n    base_model = transformers.TFAutoModel.from_pretrained(config.base)\n\n    base_model_output = base_model(\n        input_ids, attention_mask=attention_masks, token_type_ids=token_type_ids\n    )\n\n    last_hidden_state = base_model_output.last_hidden_state[:, -1, :]\n\n    dropout = tf.keras.layers.Dropout(0.1)(last_hidden_state)\n\n    dense = tf.keras.layers.Dense(base_model.config.hidden_size, activation = \"gelu\")(dropout)\n\n    dropout = tf.keras.layers.Dropout(0.1)(dense)\n\n    model_output = tf.keras.layers.Dense(1, activation = \"sigmoid\")(dropout)\n\n    model = tf.keras.models.Model(\n        inputs=[input_ids, attention_masks, token_type_ids], outputs=model_output\n    )\n\n#         optimizers = [\n#             tfa.optimizers.AdamW(weight_decay=config.weight_decay, learning_rate=config.lr1),\n#             tfa.optimizers.AdamW(weight_decay=config.weight_decay, learning_rate=config.lr2)\n#         ]\n\n    optimizers = [\n        tf.keras.optimizers.Adam(learning_rate=clr1),\n        tf.keras.optimizers.Adam(learning_rate=clr2)\n    ]\n\n    optimizers_and_layers = [(optimizers[0], model.layers[0:4]), (optimizers[1], model.layers[3:])]\n    optimizer = tfa.optimizers.MultiOptimizer(optimizers_and_layers)\n\n\n#         loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits = False)\n    loss_fn = correlationLoss\n\n    model.compile(\n        optimizer = optimizer,\n        loss=loss_fn\n    )\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:45:11.62424Z","iopub.execute_input":"2022-06-15T16:45:11.624609Z","iopub.status.idle":"2022-06-15T16:45:11.63345Z","shell.execute_reply.started":"2022-06-15T16:45:11.624573Z","shell.execute_reply":"2022-06-15T16:45:11.632613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"XL = createXL(XL_config)","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:45:11.635839Z","iopub.execute_input":"2022-06-15T16:45:11.636209Z","iopub.status.idle":"2022-06-15T16:45:11.644556Z","shell.execute_reply.started":"2022-06-15T16:45:11.636174Z","shell.execute_reply":"2022-06-15T16:45:11.643501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del createXL","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:45:11.645973Z","iopub.execute_input":"2022-06-15T16:45:11.646457Z","iopub.status.idle":"2022-06-15T16:45:11.653912Z","shell.execute_reply.started":"2022-06-15T16:45:11.646418Z","shell.execute_reply":"2022-06-15T16:45:11.652903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_inferences(XL, XL_test, XL_config, \"XLNET\")","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:45:11.655648Z","iopub.execute_input":"2022-06-15T16:45:11.656054Z","iopub.status.idle":"2022-06-15T16:45:11.662746Z","shell.execute_reply.started":"2022-06-15T16:45:11.656013Z","shell.execute_reply":"2022-06-15T16:45:11.661733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del XL, XL_config, XL_test","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:45:11.664402Z","iopub.execute_input":"2022-06-15T16:45:11.664962Z","iopub.status.idle":"2022-06-15T16:45:11.67093Z","shell.execute_reply.started":"2022-06-15T16:45:11.664913Z","shell.execute_reply":"2022-06-15T16:45:11.669741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:45:11.672797Z","iopub.execute_input":"2022-06-15T16:45:11.673212Z","iopub.status.idle":"2022-06-15T16:45:11.679808Z","shell.execute_reply.started":"2022-06-15T16:45:11.673156Z","shell.execute_reply":"2022-06-15T16:45:11.678717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_predictions = np.mean(np.array(inferences), axis = 0)","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:45:11.681577Z","iopub.execute_input":"2022-06-15T16:45:11.681981Z","iopub.status.idle":"2022-06-15T16:45:11.68781Z","shell.execute_reply.started":"2022-06-15T16:45:11.681942Z","shell.execute_reply":"2022-06-15T16:45:11.68675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_predictions","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:45:11.689804Z","iopub.execute_input":"2022-06-15T16:45:11.69029Z","iopub.status.idle":"2022-06-15T16:45:11.699245Z","shell.execute_reply.started":"2022-06-15T16:45:11.690244Z","shell.execute_reply":"2022-06-15T16:45:11.698053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv(\"../input/us-patent-phrase-to-phrase-matching/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:45:11.701124Z","iopub.execute_input":"2022-06-15T16:45:11.701576Z","iopub.status.idle":"2022-06-15T16:45:11.712922Z","shell.execute_reply.started":"2022-06-15T16:45:11.701535Z","shell.execute_reply":"2022-06-15T16:45:11.711694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"buckets = np.array([0, 0.25, 0.5, 0.75, 1])\nprocessed_predictions = [buckets[(np.abs(buckets - i)).argmin()] for i in final_predictions]","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:45:11.714661Z","iopub.execute_input":"2022-06-15T16:45:11.715085Z","iopub.status.idle":"2022-06-15T16:45:11.735251Z","shell.execute_reply.started":"2022-06-15T16:45:11.715044Z","shell.execute_reply":"2022-06-15T16:45:11.728122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"processed_predictions","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:45:11.736578Z","iopub.execute_input":"2022-06-15T16:45:11.736881Z","iopub.status.idle":"2022-06-15T16:45:11.75042Z","shell.execute_reply.started":"2022-06-15T16:45:11.736854Z","shell.execute_reply":"2022-06-15T16:45:11.749089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output = pd.concat([test.id, pd.Series(processed_predictions, name = \"score\")], axis=1).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:45:11.752495Z","iopub.execute_input":"2022-06-15T16:45:11.753413Z","iopub.status.idle":"2022-06-15T16:45:11.764306Z","shell.execute_reply.started":"2022-06-15T16:45:11.75337Z","shell.execute_reply":"2022-06-15T16:45:11.763241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:45:11.766199Z","iopub.execute_input":"2022-06-15T16:45:11.766645Z","iopub.status.idle":"2022-06-15T16:45:11.775278Z","shell.execute_reply.started":"2022-06-15T16:45:11.766606Z","shell.execute_reply":"2022-06-15T16:45:11.774223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output","metadata":{"execution":{"iopub.status.busy":"2022-06-15T16:45:11.777035Z","iopub.execute_input":"2022-06-15T16:45:11.777541Z","iopub.status.idle":"2022-06-15T16:45:11.797231Z","shell.execute_reply.started":"2022-06-15T16:45:11.777499Z","shell.execute_reply":"2022-06-15T16:45:11.796224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}